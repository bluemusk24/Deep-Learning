{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9bfd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f976eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea284f",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1fa048",
   "metadata": {},
   "source": [
    "##### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d9d5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ac8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the cnn\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#add the convolutional layer with 32 filters, kernel_size and activation function\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(150,150,3)))\n",
    "\n",
    "#size reduction of the feature maps with max pooling\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#add flatten layer to turn the multi-dimensional result into vectors\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#add Dense layers with their respective neurons and activation functions\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a87afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile loss function and optimizer\n",
    "\n",
    "loss = keras.losses.binary_crossentropy\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e88d7e9",
   "metadata": {},
   "source": [
    "#### Question 2: What's the number of parameters in the convolutional layer of our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc527c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 175232)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb1d3e6",
   "metadata": {},
   "source": [
    "#### Generators and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76836b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d9a1f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x7f47307f2d00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating the training data\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory('./data/train',\n",
    "                                         target_size=(150,150), batch_size=20, shuffle=True, class_mode='binary')\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7dbf810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x7f47307f2340>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating the testing data\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_ds = test_gen.flow_from_directory('./data/test',\n",
    "                                         target_size=(150,150), batch_size=20, shuffle=True, class_mode='binary')\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e2c3df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 23:06:46.246579: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-11-19 23:06:46.880473: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-19 23:06:46.880990: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-19 23:06:46.881026: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-11-19 23:06:46.881504: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-19 23:06:46.881584: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 11s 46ms/step - loss: 0.6772 - accuracy: 0.5766 - val_loss: 0.6411 - val_accuracy: 0.5948\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 8s 44ms/step - loss: 0.6059 - accuracy: 0.6652 - val_loss: 0.5618 - val_accuracy: 0.7168\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 8s 44ms/step - loss: 0.5549 - accuracy: 0.7278 - val_loss: 0.5606 - val_accuracy: 0.7320\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 8s 44ms/step - loss: 0.5328 - accuracy: 0.7457 - val_loss: 0.5347 - val_accuracy: 0.7266\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 8s 45ms/step - loss: 0.5030 - accuracy: 0.7639 - val_loss: 0.5203 - val_accuracy: 0.7527\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 8s 44ms/step - loss: 0.4853 - accuracy: 0.7781 - val_loss: 0.5392 - val_accuracy: 0.7179\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 8s 44ms/step - loss: 0.4551 - accuracy: 0.7914 - val_loss: 0.5032 - val_accuracy: 0.7603\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 8s 44ms/step - loss: 0.4271 - accuracy: 0.8091 - val_loss: 0.4950 - val_accuracy: 0.7702\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 8s 44ms/step - loss: 0.4163 - accuracy: 0.8257 - val_loss: 0.5400 - val_accuracy: 0.7473\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 8s 45ms/step - loss: 0.3810 - accuracy: 0.8423 - val_loss: 0.4906 - val_accuracy: 0.7734\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "history = model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963eaef",
   "metadata": {},
   "source": [
    "#### Question 3: What is the median of training accuracy for all the epochs for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45eee336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7710089683532715"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_train = np.median(history.history['accuracy'])\n",
    "median_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7c0a0",
   "metadata": {},
   "source": [
    "#### Question 4: Standard deviation of training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d32f8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08676014144609222"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_train = np.std(history.history['loss'])\n",
    "std_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6d958",
   "metadata": {},
   "source": [
    "### Data Augmentation: \n",
    "#rotation_range=50, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True, fill_mode='nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4072acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#generating the  augmented training data\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./255, rotation_range=50, width_shift_range=0.1,\n",
    "                              height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "train_ds = train_gen.flow_from_directory('./data/train',\n",
    "                                         target_size=(150,150), batch_size=20, shuffle=True, class_mode='binary')\n",
    "\n",
    "#generating the testing data\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_ds = test_gen.flow_from_directory('./data/test',\n",
    "                                         target_size=(150,150), batch_size=20, shuffle=True, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf08c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.4941 - accuracy: 0.7623 - val_loss: 0.5177 - val_accuracy: 0.7484\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.4937 - accuracy: 0.7642 - val_loss: 0.5131 - val_accuracy: 0.7691\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 23s 124ms/step - loss: 0.4798 - accuracy: 0.7803 - val_loss: 0.5801 - val_accuracy: 0.7190\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 23s 124ms/step - loss: 0.4760 - accuracy: 0.7770 - val_loss: 0.4677 - val_accuracy: 0.7789\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.4670 - accuracy: 0.7854 - val_loss: 0.5175 - val_accuracy: 0.7582\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.4725 - accuracy: 0.7786 - val_loss: 0.4704 - val_accuracy: 0.7843\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.4669 - accuracy: 0.7914 - val_loss: 0.4852 - val_accuracy: 0.7669\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.4653 - accuracy: 0.7890 - val_loss: 0.4625 - val_accuracy: 0.7843\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.4553 - accuracy: 0.7977 - val_loss: 0.5745 - val_accuracy: 0.7440\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 23s 123ms/step - loss: 0.4441 - accuracy: 0.7968 - val_loss: 0.5038 - val_accuracy: 0.7680\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "history = model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732a976a",
   "metadata": {},
   "source": [
    "#### Question 5: Mean of validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb2c0654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5092358499765396"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_val = np.mean(history.history['val_loss'])\n",
    "mean_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa65d3b7",
   "metadata": {},
   "source": [
    "#### Question 6: Avg validation accuracy for epochs 6-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ac43183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7843137383460999,\n",
       " 0.7668845057487488,\n",
       " 0.7843137383460999,\n",
       " 0.7440087199211121,\n",
       " 0.7679738402366638]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_six_to_ten = history.history['val_accuracy'][5:]\n",
    "epoch_six_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9429b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7694989085197449"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_epoch_six_to_ten = np.mean(epoch_six_to_ten)\n",
    "mean_epoch_six_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a639f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
